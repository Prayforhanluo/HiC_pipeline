#!/usr/bin/env python

# Created on Tue Dec 16 10:22:41 2014

# Author: XiaoTao Wang
# Organization: HuaZhong Agricultural University

import argparse, sys, logging, logging.handlers

def getargs():
    ## Construct an ArgumentParser object for command-line arguments
    parser = argparse.ArgumentParser(description = '''This software is based on hiclib
                                    (https://bitbucket.org/mirnylab/hiclib), a comprehensive Python package
                                    for Hi-C data analysis.''',
                                    formatter_class = argparse.ArgumentDefaultsHelpFormatter)
    
    # Version
    parser.add_argument('-v', '--version', action = 'version', version = '%(prog)s 0.1.0',
                        help = 'Print version number and exit')
    
    ## Sub-commands
    subparser = parser.add_subparsers(title = 'sub-commands',
                                      description = '''Read pair mapping, filtering, binning and iterative
                                      correction are contained. You can perform each stage of the analysis
                                      separately, or streamline the pipeline using "pileup" subcommand.''',
                                      dest = 'subcommand')
    ## Iterative Mapping
    mapping = subparser.add_parser('mapping',
                                   help = '''Map raw pair-end sequencing data to a supplied genome. Both SRA
                                   and FASTQ format are admissible.''',
                                   description = '''An iterative mapping schema is used. The minimum length
                                   is always 25, then the step will be calculated automatically based on the
                                   sequence length. The bowtie2 mapping software and a fastq-dump tool from
                                   SRA toolkit are required. At least, you should specify --fastqDir, --genomeName,
                                   --bowtiePath and --dataFolder yourself.''',
                                   epilog = '''After this command, a BAM folder containing BAM files for each side
                                   of Hi-C molecules and a HDF5 folder containing hdf5 (dict-like structure format)
                                   files for library of matched Hi-C reads are created under current working directory.''')
    mapping.add_argument('-p', '--dataFolder', default = '.',
                         help = 'Root directory of original data. We recommend placing sequencing and genome '
                                'data here.')
    mapping.add_argument('-g', '--genomeName',
                         help = '''Genome folder name. This folder must be placed under dataFolder. Genome
                         sequences should be stored chromosome by chromosome. If gap file is not contained,
                         we will generate a dummy one.''')
    mapping.add_argument('-f', '--fastqDir', help = 'Sequencing data folder. Relative path to dataFolder')
    mapping.add_argument('-F', '--Format', default = 'SRA', choices = ['SRA', 'FASTQ'],
                         help = 'Format of the sequencing data.')
    mapping.add_argument('-b', '--bowtiePath', help = 'Path to bowtie2 executable program file.')
    mapping.add_argument('-t', '--threads', type = int, default = 4, help = 'Number bowtie2 threads.')
    mapping.add_argument('-i', '--bowtieIndex',
                         help = '''Path to the bowtie2 genome index. Since the index consists of several files
                         with the different suffices (e.g., hg19.1.bt2, hg19.2.bt.2), provide only the common
                         part. For example, if your genome data hg19.fa and corresponding index files are stored
                         in ~/data/hg19, you need to specify --bowtieIndex as this "--bowtieIndex ~/data/hg19/hg19".
                         When not specified, we will generate one under the genome folder.''')
    mapping.add_argument('--cache', default = '/tmp', help = 'Set the cache folder.')
    
    ## Merge files from the same experiment
    merge = subparser.add_parser('merge',
                                 help = '''Merge files corresponding to the same experiment together.''',
                                 description = '''This command is useful when you want to merge several HDF5 files
                                 belonging to the same experiment. Metadata describing each HDF5 file should be
                                 provided.''',
                                 epilog = '''A folder with one or more merged hdf5 files are generated under current
                                 working directory after this command is called.''')
    merge.add_argument('-h', '--HDF5',
                       help = '''Path to the folder with hdf5 files which are generated by mapping command.''')
    merge.add_argument('-m', '--metadata', default = 'datasets.tsv',
                       help = '''Metadata file name. Five columns are required: prefix of hdf5 file name, cell line
                       name, biological replicate label, reference genome name, and restriction enzyme name. An example
                       file is distributed along with this software, please check it.''')
    merge.add_argument('-l', '--level', type = int, default = 1, choices = [1, 2],
                       help = '''Set merging level. 1: hdf5 files from the same biological replicate will be merged,
                       2: hdf5 files from the same cell line will be merged.''')
    
    ## Fragment-level filtering
    filtering = subparser.add_parser('filtering',
                                     help = '''Filtering at the level of aligned read pairs and restriction
                                     fragments.''',
                                     description = '''PCR duplications, self-ligation products, unligated "dangling end"
                                     products, random breaks, too large and too small fragments, and fragments with
                                     high cis-to-trans ratio are all taken into account.''',
                                     epilog = '''A folder with corresponding filtered hdf5 files are generated under
                                     current working directory after calling this command.''')
    filtering.add_argument('-u', '--mergedDir',
                           help = '''Path to the merged HDF5 files generated by merge command. If the path points to
                           one file, filtering will only be performed on that file. If the path points to a folder,
                           filtering will be performed on all files contained in that folder.''')
    filtering.add_argument('--duplicates', action = 'store_false',
                           help = '''Remove read pairs resulting from PCR amplification.''')
    filtering.add_argument('--RandomBreaks', action = 'store_false',
                           help = '''Remove "random breaks" in which corresponding fragments did not arise from
                           normal restriction digestion.''')
    filtering.add_argument('--extremeFragments', action = 'store_false',
                           help = '''Remove too large and too small fragments.''')
    filtering.add_argument('--cistotrans', action = 'store_false',
                           help = '''Remove top 0.5% of fragments with the greatest number of reads.''')
    
    ## Binning
    binning = subparser.add_parser('binning',
                                   help = '''Bin filtered reads at certain resolution.''',
                                   description = '''For varying resolutions, three modes are provided, just choose a
                                   proper one.''',
                                   epilog = '''After calling this command, a folder with created HeatMaps (in HDF5 format)
                                   is created under current working directory.''')
    binning.add_argument('-f', '--filteredDir',
                         help = '''Path to the filtered HDF5 files generated by filtering command. If the path points to
                         one file, we will only create a HeatMap for that file. If the path points to a folder, we will
                         construct a HeatMap for each file in that folder.''')
    binning.add_argument('-M', '--mode', default = 'wholeGenome', choices = ['wholeGenome', 'byChromosome', 'withOverlaps'],
                         help = '''Memory usage: withOverlaps > byChromosome > wholeGenome. Resolution capacity:
                         withOverlaps (10kb) > byChromosome (40kb) > wholeGenome (200kb).''')
    binning.add_argument('-R', '--resolution', type = int, default = 200000,
                         help = 'Resolution of a heatmap. Unit: bp')
    
    ## Iterative Correction
    correction = subparser.add_parser('correction',
                                      help = '''Perform iterative corrections on the original HeatMap.''',
                                      description = '''Two modes are provided for different resolutions.''',
                                      epilog = '''After calling this command, a folder with corrected HeatMaps (in HDF5
                                      format) is created under current working directory.''')
    correction.add_argument('-H', '--HeatMap',
                            help = '''Path to the HeatMap files generated by binning command. If the path points to one
                            file, we only correct for that HeatMap. If the path points to a folder, we will perform iterative
                            correction for all HeaMaps in that folder.''')
    mg = correction.add_mutually_exclusive_group(required = True)
    mg.add_argument('--lowRes', action = 'store_true',
                    help = '''Suitable for low-resolution cases and all-by-all HeatMaps.''')
    mg.add_argument('--highRes', action = 'store_true',
                    help = '''Suitable for high-resolution and chromosome-by-chromosome HeatMaps.''')
                    
    ## Pile Up
    pileup = subparser.add_parser('pileup',
                                  parents = [mapping],
                                  help = 'Perform the entire analysis from sequencing data to corrected HeatMaps.',
                                  description = '''A more convenient but less flexible command for Hi-C data processing.''')
    pileup.add_argument('-m', '-metadata', default = 'datasets.tsv',
                       help = '''Metadata file name. Describing each SRA file. Five columns are required: prefix of SRA file
                       name, cell line name, biological replicate label, reference genome name, and restriction enzyme name.
                       An example file is distributed along with this software, please check it.''')